# -*- coding: utf-8 -*-
"""spotify Collaborative Filtering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1le6QOnVpCgmMDqGGJOmAbh4pa_WhX-KS
"""

! pip install kagglehub --upgrade

#download dataset from kaggle
import kagglehub

kagglehub.dataset_download("undefinenull/million-song-dataset-spotify-lastfm")

from pathlib import Path
data_path = Path('/kaggle/input/million-song-dataset-spotify-lastfm')

# List all files in the directory
for file in data_path.iterdir():
    print(file)

import pandas as pd

songs_data_path='/kaggle/input/million-song-dataset-spotify-lastfm/Music Info.csv'
songs_df=pd.read_csv(songs_data_path,usecols=['track_id','name','artist','spotify_preview_url'])
songs_df.head()

!pip install dask[dataframe]

import dask.dataframe as dd
df=dd.read_csv('/kaggle/input/million-song-dataset-spotify-lastfm/User Listening History.csv')
df.head()

df.visualize(tasks=True)

#fatch unique track ids from data frame
unique_tracks=df.loc[:,'track_id'].nunique()
unique_tracks=unique_tracks.compute()

unique_tracks

unique_users=df.loc[:,'user_id'].nunique()
unique_users=unique_users.compute()

unique_users

unique_track_ids=df.loc[:,'track_id'].unique().compute().tolist()

filtered_songs=songs_df[songs_df['track_id'].isin(unique_track_ids)]
filtered_songs.reset_index(drop=True,inplace=True)

filtered_songs

df.head()

#ensure the playground as int
df['playcount']=df['playcount'].astype(np.float64)

df=df.categorize(columns=['track_id','user_id'])

user_mapping=df['user_id'].cat.codes
track_mapping=df['track_id'].cat.codes

df=df.assign(user_id_idx=user_mapping,track_id_idx=track_mapping)

df.visualize(tasks=True)

interaction_array=df.groupby(['track_id_idx','user_id_idx'])['playcount'].sum().reset_index()
interaction_array=interaction_array.compute()

from scipy.sparse import csr_matrix

# Assuming interaction_array is a pandas DataFrame with the required columns
row_indices = interaction_array['track_id_idx'].values
col_indices = interaction_array['user_id_idx'].values
values = interaction_array['playcount'].values

n_tracks = unique_tracks
n_users = unique_users


sparse_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(n_tracks, n_users))

print("Sparse matrix shape:", sparse_matrix.shape)
print("Non-zero elements:", sparse_matrix.nnz)

sparse_matrix[0]

from sklearn.metrics.pairwise import cosine_similarity

import numpy as np
np.where(df['track_id'].cat.categories=='TRHDDQG12903CB53EE')

ind=8936
input_vector=sparse_matrix[ind]
similarity_scores=cosine_similarity(input_vector,sparse_matrix)

np.sort(similarity_scores)[-6:][::-1]

similarity_scores.shape

np.argsort(similarity_scores.ravel())[::-6][::-1]

recommandations=df['track_id'].cat.categories[np.argsort(similarity_scores.ravel())[-6:][::-1]]

recommandations

#filtered_songs[filtered_songs["name"] == "Crazy in Love"]

filtered_songs[filtered_songs["track_id"].isin(recommandations)]

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd

def collaborative_recommendations(song_name, user_data, song_data, interaction_matrix, k=5):
    # Fetch the row from song_data
    song_row = song_data[song_data['name'] == song_name]

    if song_row.empty:
        print(f"Song '{song_name}' not found in song_data.")
        return pd.DataFrame()

    # Extract track_id
    input_track_id = song_row['track_id'].values[0]
    print(f"Input Track ID: {input_track_id}")

    # Get index of the input track in the interaction matrix
    if not pd.api.types.is_categorical_dtype(user_data['track_id']):
        print("user_data['track_id'] must be a categorical dtype.")
        return pd.DataFrame()

    try:
        track_idx = user_data['track_id'].cat.categories.get_loc(input_track_id)
    except KeyError:
        print(f"Track ID {input_track_id} not found in user_data['track_id'].categories.")
        return pd.DataFrame()

    print(f"Track Index in Matrix: {track_idx}")

    # Fetch the input array
    input_array = interaction_matrix[track_idx]

    # Compute similarity
    similarity_scores = cosine_similarity(input_array, interaction_matrix).flatten()

    # Get top-k similar indices (excluding the track itself)
    top_k_idx = np.argsort(similarity_scores)[::-1][1:k+1]

    # Get recommended track IDs
    recommended_track_ids = user_data['track_id'].cat.categories[top_k_idx]
    print(f"Recommended Track IDs: {recommended_track_ids}")

    # Corresponding similarity scores
    top_scores = similarity_scores[top_k_idx]
    print(f"Top Similarity Scores: {top_scores}")

    # Join with song_data to get details
    temp_df = pd.DataFrame({
        "track_id": recommended_track_ids,
        "score": top_scores
    })

    top_k_songs = (
        song_data[song_data["track_id"].isin(recommended_track_ids)]
        .merge(temp_df, on="track_id")
        .sort_values(by="score", ascending=False)
        .drop(columns=["track_id", "score"])
        .reset_index(drop=True)
    )

    return top_k_songs

collaborative_recommendations(song_name="Mr. Brightside",
                             user_data=df,
                             song_data=filtered_songs,
                             interaction_matrix=sparse_matrix)

